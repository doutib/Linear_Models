# Negative log likelihood
loss = function(beta){
x = design %*% beta
-(sum(Y*log(Eta(x))+(1-Y)*log(1-Eta(x))))
}
beta0 = as.matrix(rep(0,dim(design)[2]))
loss(beta0)
mini = fminsearch(loss,beta0)
beta_hat = mini$xval
names(beta_hat) <- names_features
beta_hat
## Alternative
glm.fit <- glm(LABSTAT ~. , data = features, family = "binomial")
summary(glm.fit)
# Split age
split_age1 = rep(0,length(data$AGE))
split_age2 = rep(0,length(data$AGE))
split_age3 = rep(0,length(data$AGE))
split_age4 = rep(0,length(data$AGE))
split_age1[data$AGE>=16 & data$AGE<=19] = 1#"16-19"
split_age2[data$AGE>=20 & data$AGE<=39] = 1#"20–39"
split_age3[data$AGE>=40 & data$AGE<=64] = 1#"40-64"
split_age4[data$AGE>=65] = 1#"65+"
# Split Race
split_race = rep(0,length(data$RACE))
split_race[data$RACE==1] = 1#"white"
# Split Education level
split_edlevel1 = rep(0,length(data$EDLEVEL))
split_edlevel2 = rep(0,length(data$EDLEVEL))
split_edlevel3 = rep(0,length(data$EDLEVEL))
split_edlevel1[data$EDLEVEL<=38] = 1#"HS-"
split_edlevel2[data$EDLEVEL==39] = 1#"HS "
split_edlevel3[data$EDLEVEL>=40] = 1#"HS+"
# Split SEX
split_sex = rep(NA,length(data$SEX))
split_sex[data$SEX==1]=0#"M"
split_sex[data$SEX==2]=1#"F"
features = data.frame(LABSTAT = as.numeric(data$LABSTAT==1),
SEX = as.numeric(split_sex),
AGE1 = as.numeric(split_age1),
AGE2 = as.numeric(split_age2),
AGE3 = as.numeric(split_age3),
AGE4 = as.numeric(split_age4),
RACE = as.numeric(split_race),
EDLEVEL1 = as.numeric(split_edlevel1),
EDLEVEL2 = as.numeric(split_edlevel2),
EDLEVEL3 = as.numeric(split_edlevel3))
head(features)
any(is.na(features))
## # 1.
design = features[,-1]
design$Intercept = as.numeric(1)
head(design)
names_features = names(design)
design = as.matrix(design)
# Size of design matrix
dim(design)
Y=features[,1]
## # 2.
library(pracma)
Eta = function(x){
sapply(x,function(x) 1/(1+exp(-x)))
}
# Negative log likelihood
loss = function(beta){
x = design %*% beta
-(sum(Y*log(Eta(x))+(1-Y)*log(1-Eta(x))))
}
beta0 = as.matrix(rep(0,dim(design)[2]))
loss(beta0)
mini = fminsearch(loss,beta0)
beta_hat = mini$xval
names(beta_hat) <- names_features
beta_hat
### ## ### LAB 11 ### ## ###
# Compute log likelihood
log_likelihood_aux = function(theta,X){
n = lengthgth(X)
n*log(theta) - 2*sum(log(theta+X))
}
log_likelihood = Vectorize(log_likelihood_aux)
# Change variable theta<-exp(phi)
log_likelihood_phi_aux = function(phi,X){
n = length(X)
n*phi - 2*sum(log(exp(phi)+X))
}
MLE = function (X){
f = function(phi){-log_likelihood_phi_aux(phi,X)}
opt = optim(0,f,
method="Brent",
lower = 0,
upper = 10)
theta_hat = exp(opt$par)
theta_hat
}
## # 1-3. Generate uniform RV
set.seed(1)
theta_hat_values = c()
for (i in 1:1000){
# Generate data
U = runif(50)
theta = 25
X = theta*sapply(U,function(x) x/(1-x))
# Compute MLE
theta_hat = MLE(X)
theta_hat_values = c(theta_hat_values,theta_hat)
}
## # 4. Plot histogram
hist(theta_hat_values,
xlab = "theta_hat",
main = "Realizations of MLE")
## # 5. Mean/SD
mu = mean(theta_hat_values)
mu
sigma = sd(theta_hat_values)
sigma
fisher_info = function(theta){
1/(3*theta^2)
}
# Comparison
asympt_var = 1/sqrt(50*sapply(theta_hat_values,fisher_info))
sigma
hist(asympt_var,
main = "Comparison of the two quantities")
abline(v=sigma,lty=2,lwd=3)
text(sigma,100,"SD of\ntheta_hat\n",pos=2)
abline(v=mean(asympt_var),lwd=3)
text(mean(asympt_var),20,"Mean of distribution",pos=4)
mean(asympt_var)
mean(asympt_var)-sigma
# The asymptotic variance is equal to 1/sqrt(...)
# Therefore they shoud be equal for an infinite
# number of simulations
# c.f. formula Example 4, Chapter 7
## # 6.
## # 7.
### ## ### LAB 12 ### ## ###
data = read.table("pac01.dat")
head(data)
names(data)=c("AGE",
"SEX",
"RACE",
"ETHNICITY",
"MARITAL",
"NUMKIDS",
"FAMPERS",
"EDLEVEL",
"LABSTAT",
"CLASSWORK",
"FULLPART",
"HOURS",
"WHYNOTWORK",
"INSCHOOL",
"INDUSTRY",
"OCCUPATION",
"PINCOME",
"INCFAM",
"CITIZEN",
"IMMIGYR",
"HHSEQNUM",
"FSEQNUM",
"PERSCODE",
"SPOUCODE",
"FINALWGT",
"MARCHWGT",
"STATE")
head(data)
subset = data[,c("LABSTAT","AGE","SEX","RACE","EDLEVEL")]
head(subset)
# Split age
split_age1 = rep(0,length(data$AGE))
split_age2 = rep(0,length(data$AGE))
split_age3 = rep(0,length(data$AGE))
split_age1[data$AGE>=20 & data$AGE<=39] = 1#"20–39"
split_age2[data$AGE>=40 & data$AGE<=64] = 1#"40-64"
split_age3[data$AGE>=65] = 1#"65+"
# Split Race
split_race = rep(0,length(data$RACE))
split_race[data$RACE!=1] = 1#"white"
# Split Education level
split_edlevel1 = rep(0,length(data$EDLEVEL))
split_edlevel2 = rep(0,length(data$EDLEVEL))
split_edlevel1[data$EDLEVEL==39] = 1#"HS "
split_edlevel2[data$EDLEVEL>=40] = 1#"HS+"
# Split SEX
split_sex = rep(NA,length(data$SEX))
split_sex[data$SEX==1]=0#"M"
split_sex[data$SEX==2]=1#"F"
features = data.frame(LABSTAT = as.numeric(data$LABSTAT==1),
SEX = as.numeric(split_sex),
AGE1 = as.numeric(split_age1),
AGE2 = as.numeric(split_age2),
AGE3 = as.numeric(split_age3),
RACE = as.numeric(split_race),
EDLEVEL1 = as.numeric(split_edlevel1),
EDLEVEL2 = as.numeric(split_edlevel2))
head(features)
any(is.na(features))
## # 1.
design = features[,-1]
design$Intercept = as.numeric(1)
head(design)
names_features = names(design)
design = as.matrix(design)
# Size of design matrix
dim(design)
Y=features[,1]
## # 2.
library(pracma)
Eta = function(x){
sapply(x,function(x) 1/(1+exp(-x)))
}
# Negative log likelihood
loss = function(beta){
x = design %*% beta
-(sum(Y*log(Eta(x))+(1-Y)*log(1-Eta(x))))
}
beta0 = as.matrix(rep(0,dim(design)[2]))
loss(beta0)
mini = fminsearch(loss,beta0)
beta_hat = mini$xval
names(beta_hat) <- names_features
beta_hat
glm.fit <- glm(LABSTAT ~. , data = features, family = "binomial")
summary(glm.fit)
summary(glm.fit)$coefficients
names(summary(glm.fit)$coefficients)
summary(glm.fit)$coefficients[,2]
head(features)
head(data)
summary(glm.fit)
# Compute log likelihood
log_likelihood_aux = function(theta,X){
n = lengthgth(X)
n*log(theta) - 2*sum(log(theta+X))
}
log_likelihood = Vectorize(log_likelihood_aux)
# Change variable theta<-exp(phi)
log_likelihood_phi_aux = function(phi,X){
n = length(X)
n*phi - 2*sum(log(exp(phi)+X))
}
MLE = function (X){
f = function(phi){-log_likelihood_phi_aux(phi,X)}
opt = optim(0,f,
method="Brent",
lower = 0,
upper = 10)
theta_hat = exp(opt$par)
theta_hat
}
## # 1-3. Generate uniform RV
set.seed(1)
theta_hat_values = c()
for (i in 1:1000){
# Generate data
U = runif(50)
theta = 25
X = theta*sapply(U,function(x) x/(1-x))
# Compute MLE
theta_hat = MLE(X)
theta_hat_values = c(theta_hat_values,theta_hat)
}
## # 4. Plot histogram
hist(theta_hat_values,
xlab = "theta_hat",
main = "Realizations of MLE")
## # 5. Mean/SD
mu = mean(theta_hat_values)
mu
sigma = sd(theta_hat_values)
sigma
fisher_info = function(theta){
1/(3*theta^2)
}
# Comparison
asympt_var = 1/sqrt(50*sapply(theta_hat_values,fisher_info))
sigma
hist(asympt_var,
main = "Comparison of the two quantities")
abline(v=sigma,lty=2,lwd=3)
text(sigma,100,"SD of\ntheta_hat\n",pos=2)
abline(v=mean(asympt_var),lwd=3)
text(mean(asympt_var),20,"Mean of distribution",pos=4)
mean(asympt_var)
mean(asympt_var)-sigma
mean(asympt_var)
sigma
asympt_var = 1/sqrt(50*fisher_info(25))
asympt_var
asympt_var = 1/sqrt(50*fisher_info(25))
sigma
hist(asympt_var,
main = "Comparison of the two quantities")
sigma
asympt_var = 1/sqrt(50*fisher_info(25))
sigma
asympt_var-sigma
asympt_var = 1/sqrt(50*fisher_info(25))
asympt_var
asympt_var = 1/sqrt(50*fisher_info(50))
asympt_var
fisher_info(25)
fisher_info(50)
asympt_var = 1/sqrt(50*fisher_info(25))
asympt_var
asympt_var = 1/sqrt(50*fisher_info(50))
asympt_var
asympt_var = 1/sqrt(50*fisher_info(25))
fisher_info(25)
fisher_info(50)
fisher_info(25)/fisher_info(50)
fisher_info(25)/fisher_info(50)
fisher_info(25)
fisher_info(50)
for (i in 1:1000){
# Generate data
U = runif(50)
theta = 50
X = theta*sapply(U,function(x) x/(1-x))
# Compute MLE
theta_hat = MLE(X)
theta_hat_values = c(theta_hat_values,theta_hat)
}
## # 4. Plot histogram
hist(theta_hat_values,
xlab = "theta_hat",
main = "Realizations of MLE")
## # 5. Mean/SD
mu = mean(theta_hat_values)
mu
sigma = sd(theta_hat_values)
sigma
fisher_info = function(theta){
1/(3*theta^2)
}
# Comparison
asympt_var = 1/sqrt(50*fisher_info(25))
sigma
asympt_var-sigma
asympt_var = 1/sqrt(50*fisher_info(50))
sigma
asympt_var
sigma
for (i in 1:1000){
# Generate data
U = runif(50)
theta = 25
X = theta*sapply(U,function(x) x/(1-x))
# Compute MLE
theta_hat = MLE(X)
theta_hat_values = c(theta_hat_values,theta_hat)
}
## # 4. Plot histogram
hist(theta_hat_values,
xlab = "theta_hat",
main = "Realizations of MLE")
## # 5. Mean/SD
mu = mean(theta_hat_values)
mu
sigma = sd(theta_hat_values)
sigma
fisher_info = function(theta){
1/(3*theta^2)
}
# Comparison
asympt_var = 1/sqrt(50*fisher_info(50))
sigma
asympt_var = 1/sqrt(50*fisher_info(25))
sigma
asympt_var-sigma
### ## ### LAB 11 ### ## ###
# Compute log likelihood
log_likelihood_aux = function(theta,X){
n = lengthgth(X)
n*log(theta) - 2*sum(log(theta+X))
}
log_likelihood = Vectorize(log_likelihood_aux)
# Change variable theta<-exp(phi)
log_likelihood_phi_aux = function(phi,X){
n = length(X)
n*phi - 2*sum(log(exp(phi)+X))
}
MLE = function (X){
f = function(phi){-log_likelihood_phi_aux(phi,X)}
opt = optim(0,f,
method="Brent",
lower = 0,
upper = 10)
theta_hat = exp(opt$par)
theta_hat
}
## # 1-3. Generate uniform RV
set.seed(1)
theta_hat_values = c()
for (i in 1:1000){
# Generate data
U = runif(50)
theta = 25
X = theta*sapply(U,function(x) x/(1-x))
# Compute MLE
theta_hat = MLE(X)
theta_hat_values = c(theta_hat_values,theta_hat)
}
## # 4. Plot histogram
hist(theta_hat_values,
xlab = "theta_hat",
main = "Realizations of MLE")
## # 5. Mean/SD
mu = mean(theta_hat_values)
mu
sigma = sd(theta_hat_values)
sigma
fisher_info = function(theta){
1/(3*theta^2)
}
# Comparison
asympt_var = 1/sqrt(50*fisher_info(25))
sigma
### ## ### LAB 11 ### ## ###
# Compute log likelihood
log_likelihood_aux = function(theta,X){
n = lengthgth(X)
n*log(theta) - 2*sum(log(theta+X))
}
log_likelihood = Vectorize(log_likelihood_aux)
# Change variable theta<-exp(phi)
log_likelihood_phi_aux = function(phi,X){
n = length(X)
n*phi - 2*sum(log(exp(phi)+X))
}
MLE = function (X){
f = function(phi){-log_likelihood_phi_aux(phi,X)}
opt = optim(0,f,
method="Brent",
lower = 0,
upper = 10)
theta_hat = exp(opt$par)
theta_hat
}
## # 1-3. Generate uniform RV
set.seed(1)
theta_hat_values = c()
for (i in 1:1000){
# Generate data
U = runif(50)
theta = 50
X = theta*sapply(U,function(x) x/(1-x))
# Compute MLE
theta_hat = MLE(X)
theta_hat_values = c(theta_hat_values,theta_hat)
}
## # 4. Plot histogram
hist(theta_hat_values,
xlab = "theta_hat",
main = "Realizations of MLE")
## # 5. Mean/SD
mu = mean(theta_hat_values)
mu
sigma = sd(theta_hat_values)
sigma
### ## ### LAB 11 ### ## ###
# Compute log likelihood
log_likelihood_aux = function(theta,X){
n = lengthgth(X)
n*log(theta) - 2*sum(log(theta+X))
}
log_likelihood = Vectorize(log_likelihood_aux)
# Change variable theta<-exp(phi)
log_likelihood_phi_aux = function(phi,X){
n = length(X)
n*phi - 2*sum(log(exp(phi)+X))
}
MLE = function (X){
f = function(phi){-log_likelihood_phi_aux(phi,X)}
opt = optim(0,f,
method="Brent",
lower = 0,
upper = 10)
theta_hat = exp(opt$par)
theta_hat
}
## # 1-3. Generate uniform RV
set.seed(1)
theta_hat_values = c()
for (i in 1:1000){
# Generate data
U = runif(50)
theta = 25
X = theta*sapply(U,function(x) x/(1-x))
# Compute MLE
theta_hat = MLE(X)
theta_hat_values = c(theta_hat_values,theta_hat)
}
## # 4. Plot histogram
hist(theta_hat_values,
xlab = "theta_hat",
main = "Realizations of MLE")
## # 5. Mean/SD
mu = mean(theta_hat_values)
mu
sigma = sd(theta_hat_values)
sigma
fisher_info = function(theta){
1/(3*theta^2)
}
# Comparison
asympt_var = 1/sqrt(50*fisher_info(25))
sigma
asympt_var
sigma
dim(design)
