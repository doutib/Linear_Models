formula = paste(formula,"-",next_to_remove,sep="")
# Update model using new formula
lm.fit = update(lm.fit, formula)
}
# Intercept only
variables = variables
MSE = MSE_cv(data, nfold, formula)
MSE_test = c(MSE_test, MSE)
AIC = c(AIC,AIC(lm.fit))
BIC = c(BIC,BIC(lm.fit))
Cp = c(Cp, MSE)
return(list(variables = rev(variables), MSE_test = MSE_test,
AIC=AIC, BIC=BIC, Cp=Cp))
}
backward = backward_lm(data)
set.seed(1)
data=makedata()
lmout=lm(Y~.,data=data)
summary(lmout)
coef(summary(lmout))[-1,]
backward_lm = function(data,nfold=10){
# Initialize with OLS
formula = "Y~."
lm.fit = lm(formula, data=data)
# Initialize outputs
MSE_test = c()
AIC = c()
BIC = c()
Cp = c()
next_to_remove = ""
variables = c()
n = nrow(data)
while(length(names(lm.fit$model))>1){
print(coef(summary(lm.fit))[-1,])
MSE = MSE_cv(data, nfold=nfold, formula)
MSE_test = c(MSE_test, MSE)
AIC = c(AIC,AIC(lm.fit))
BIC = c(BIC,BIC(lm.fit))
d = length(names(lm.fit$coefficients))-1
Cp = c(Cp, MSE + 2*d*mean((lm.fit$residuals)^2)/n)
t_values = coef(summary(lm.fit))[, "t value"]
# Variable with smallest t-value
next_to_remove = names(which.min(t_values[-1]))
# Store removed variables in the order
variables = c(variables,next_to_remove)
# Update formula
formula = paste(formula,"-",next_to_remove,sep="")
# Update model using new formula
lm.fit = update(lm.fit, formula)
}
# Intercept only
variables = variables
MSE = MSE_cv(data, nfold, formula)
MSE_test = c(MSE_test, MSE)
AIC = c(AIC,AIC(lm.fit))
BIC = c(BIC,BIC(lm.fit))
Cp = c(Cp, MSE)
return(list(variables = rev(variables), MSE_test = MSE_test,
AIC=AIC, BIC=BIC, Cp=Cp))
}
backward = backward_lm(data)
rm(list = ls())
cat("\014")
# Data --------------------------------------------------------------------
makedata=function(p=20,wh=15,n=100){
# This function generates p independent X variables and then uses wh of them
# to generate Y based on coefficients determined by exp(exps) below.
# Outside of the function, the data frame named data is further changed to
# randomize the order of the variables so it's hard to tell for sure which
# ones were used to generate Y.  You can always go back and examine switch
# to figure out if your models include the right variables and which ones.
X=matrix(rnorm(n*p),n,p)
exps=seq(-1,-2.5,length=wh)
beta=rep(0,p)
beta[1:wh]=exp(exps)
Y=.5+X%*%beta+rnorm(n)
data = data.frame(Y,X)
colnames(data)=c("Y",letters[1:20])
switch=sample(20)+1
data=data[,c(1,switch)]
return(data)
}
set.seed(1)
data=makedata()
lmout=lm(Y~.,data=data)
summary(lmout)
coef(summary(lmout))[-1,]
# Criteria ----------------------------------------------------------------
## # Cross validated MSE
MSE_cv = function(data, nfold=10, formula="Y~."){
Y_cv = c()
nrows = nrow(data)
MSE_test = c()
for (i in seq(0, nrows-nfold, by=nrows/nfold)){
test = (i+1):(nfold+i)
train = -test
lm.fit = lm(formula, data=data[train,])
Ytest = predict(lm.fit, data[test,])
MSE_test = c(MSE_test, mean((data$Y[test]-Ytest)^2))
}
return(mean(MSE_test))
}
MSE_cv(data)
# Backward selection ------------------------------------------------------
backward_lm = function(data,nfold=10){
# Initialize with OLS
formula = "Y~."
lm.fit = lm(formula, data=data)
# Initialize outputs
MSE_test = c()
AIC = c()
BIC = c()
Cp = c()
next_to_remove = ""
variables = c()
n = nrow(data)
while(length(names(lm.fit$model))>1){
#print(coef(summary(lm.fit))[-1,])
MSE = MSE_cv(data, nfold=nfold, formula)
MSE_test = c(MSE_test, MSE)
AIC = c(AIC,AIC(lm.fit))
BIC = c(BIC,BIC(lm.fit))
d = length(names(lm.fit$coefficients))-1
Cp = c(Cp, MSE + 2*d*mean((lm.fit$residuals)^2)/n)
t_values = coef(summary(lm.fit))[, "t value"]
# Variable with smallest t-value
next_to_remove = names(which.min(t_values[-1]))
# Store removed variables in the order
variables = c(variables,next_to_remove)
# Update formula
formula = paste(formula,"-",next_to_remove,sep="")
# Update model using new formula
lm.fit = update(lm.fit, formula)
}
# Intercept only
variables = variables
MSE = MSE_cv(data, nfold, formula)
MSE_test = c(MSE_test, MSE)
AIC = c(AIC,AIC(lm.fit))
BIC = c(BIC,BIC(lm.fit))
Cp = c(Cp, MSE)
return(list(variables = rev(variables), MSE_test = MSE_test,
AIC=AIC, BIC=BIC, Cp=Cp))
}
backward = backward_lm(data)
backward
backward_lm = function(data,nfold=10){
# Initialize with OLS
formula = "Y~."
lm.fit = lm(formula, data=data)
# Initialize outputs
MSE_test = c()
AIC = c()
BIC = c()
Cp = c()
next_to_remove = ""
variables = c()
n = nrow(data)
while(length(names(lm.fit$model))>1){
MSE = MSE_cv(data, nfold=nfold, formula)
MSE_test = c(MSE_test, MSE)
AIC = c(AIC,AIC(lm.fit))
BIC = c(BIC,BIC(lm.fit))
d = length(names(lm.fit$coefficients))-1
Cp = c(Cp, MSE + 2*d*mean((lm.fit$residuals)^2)/n)
t_values = coef(summary(lm.fit))[,"t value"]
# Variable with smallest t-value
next_to_remove = names(which.min(t_values[-1]))
print(t_values[-1])
# Store removed variables in the order
variables = c(variables,next_to_remove)
# Update formula
formula = paste(formula,"-",next_to_remove,sep="")
# Update model using new formula
lm.fit = update(lm.fit, formula)
}
# Intercept only
variables = variables
MSE = MSE_cv(data, nfold, formula)
MSE_test = c(MSE_test, MSE)
AIC = c(AIC,AIC(lm.fit))
BIC = c(BIC,BIC(lm.fit))
Cp = c(Cp, MSE)
return(list(variables = rev(variables), MSE_test = MSE_test,
AIC=AIC, BIC=BIC, Cp=Cp))
}
backward = backward_lm(data)
rm(list = ls())
cat("\014")
# Data --------------------------------------------------------------------
makedata=function(p=20,wh=15,n=100){
# This function generates p independent X variables and then uses wh of them
# to generate Y based on coefficients determined by exp(exps) below.
# Outside of the function, the data frame named data is further changed to
# randomize the order of the variables so it's hard to tell for sure which
# ones were used to generate Y.  You can always go back and examine switch
# to figure out if your models include the right variables and which ones.
X=matrix(rnorm(n*p),n,p)
exps=seq(-1,-2.5,length=wh)
beta=rep(0,p)
beta[1:wh]=exp(exps)
Y=.5+X%*%beta+rnorm(n)
data = data.frame(Y,X)
colnames(data)=c("Y",letters[1:20])
switch=sample(20)+1
data=data[,c(1,switch)]
return(data)
}
set.seed(1)
data=makedata()
lmout=lm(Y~.,data=data)
summary(lmout)
coef(summary(lmout))[-1,]
# Criteria ----------------------------------------------------------------
## # Cross validated MSE
MSE_cv = function(data, nfold=10, formula="Y~."){
Y_cv = c()
nrows = nrow(data)
MSE_test = c()
for (i in seq(0, nrows-nfold, by=nrows/nfold)){
test = (i+1):(nfold+i)
train = -test
lm.fit = lm(formula, data=data[train,])
Ytest = predict(lm.fit, data[test,])
MSE_test = c(MSE_test, mean((data$Y[test]-Ytest)^2))
}
return(mean(MSE_test))
}
MSE_cv(data)
# Backward selection ------------------------------------------------------
backward_lm = function(data,nfold=10){
# Initialize with OLS
formula = "Y~."
lm.fit = lm(formula, data=data)
# Initialize outputs
MSE_test = c()
AIC = c()
BIC = c()
Cp = c()
next_to_remove = ""
variables = c()
n = nrow(data)
while(length(names(lm.fit$model))>1){
MSE = MSE_cv(data, nfold=nfold, formula)
MSE_test = c(MSE_test, MSE)
AIC = c(AIC,AIC(lm.fit))
BIC = c(BIC,BIC(lm.fit))
d = length(names(lm.fit$coefficients))-1
Cp = c(Cp, MSE + 2*d*mean((lm.fit$residuals)^2)/n)
t_values = coef(summary(lm.fit))[,"t value"]
# Variable with smallest t-value
next_to_remove = names(which.min(t_values[-1]))
# Store removed variables in the order
variables = c(variables,next_to_remove)
# Update formula
formula = paste(formula,"-",next_to_remove,sep="")
# Update model using new formula
lm.fit = update(lm.fit, formula)
}
# Intercept only
variables = variables
MSE = MSE_cv(data, nfold, formula)
MSE_test = c(MSE_test, MSE)
AIC = c(AIC,AIC(lm.fit))
BIC = c(BIC,BIC(lm.fit))
Cp = c(Cp, MSE)
return(list(variables = rev(variables), MSE_test = MSE_test,
AIC=AIC, BIC=BIC, Cp=Cp))
}
backward = backward_lm(data)
length(backward$variables)
rm(list = ls())
cat("\014")
# Data --------------------------------------------------------------------
makedata=function(p=20,wh=15,n=100){
# This function generates p independent X variables and then uses wh of them
# to generate Y based on coefficients determined by exp(exps) below.
# Outside of the function, the data frame named data is further changed to
# randomize the order of the variables so it's hard to tell for sure which
# ones were used to generate Y.  You can always go back and examine switch
# to figure out if your models include the right variables and which ones.
X=matrix(rnorm(n*p),n,p)
exps=seq(-1,-2.5,length=wh)
beta=rep(0,p)
beta[1:wh]=exp(exps)
Y=.5+X%*%beta+rnorm(n)
data = data.frame(Y,X)
colnames(data)=c("Y",letters[1:20])
switch=sample(20)+1
data=data[,c(1,switch)]
return(data)
}
set.seed(1)
data=makedata()
lmout=lm(Y~.,data=data)
summary(lmout)
coef(summary(lmout))[-1,]
# Criteria ----------------------------------------------------------------
## # Cross validated MSE
MSE_cv = function(data, nfold=10, formula="Y~."){
Y_cv = c()
nrows = nrow(data)
MSE_test = c()
for (i in seq(0, nrows-nfold, by=nrows/nfold)){
test = (i+1):(nfold+i)
train = -test
lm.fit = lm(formula, data=data[train,])
Ytest = predict(lm.fit, data[test,])
MSE_test = c(MSE_test, mean((data$Y[test]-Ytest)^2))
}
return(mean(MSE_test))
}
MSE_cv(data)
# Backward selection ------------------------------------------------------
backward_lm = function(data,nfold=10){
# Initialize with OLS
formula = "Y~."
lm.fit = lm(formula, data=data)
# Initialize outputs
MSE_test = c()
AIC = c()
BIC = c()
Cp = c()
next_to_remove = ""
variables = c()
n = nrow(data)
while(length(names(lm.fit$model))>1){
MSE = MSE_cv(data, nfold=nfold, formula)
MSE_test = c(MSE_test, MSE)
AIC = c(AIC,AIC(lm.fit))
BIC = c(BIC,BIC(lm.fit))
d = length(names(lm.fit$coefficients))-1
Cp = c(Cp, MSE + 2*d*mean((lm.fit$residuals)^2)/n)
t_values = coef(summary(lm.fit))[,"t value"]
# Variable with smallest t-value
next_to_remove = names(which.min(t_values[-1]))
# Store removed variables in the order
variables = c(variables,next_to_remove)
# Update formula
formula = paste(formula,"-",next_to_remove,sep="")
# Update model using new formula
lm.fit = update(lm.fit, formula)
}
# Intercept only
variables = variables
MSE = MSE_cv(data, nfold, formula)
MSE_test = c(MSE_test, MSE)
AIC = c(AIC,AIC(lm.fit))
BIC = c(BIC,BIC(lm.fit))
Cp = c(Cp, MSE)
return(list(variables = rev(variables), MSE_test = MSE_test,
AIC=AIC, BIC=BIC, Cp=Cp))
}
backward = backward_lm(data)
backward_data = function(n=100,nfold=10){
data = makedata(n=n)
return(backward_lm(data,nfold=nfold))
}
R = replicate(5,backward_data(n=100))
MSE_values = matrix(unlist(R["MSE_test",]), nrow = 3, byrow = T)
MSE_values
MSE_values = matrix(unlist(R["MSE_test",]), nrow = 5, byrow = T)
MSE_values
library(parallel)
metric_values = function(B=3,n=100){
cl = makeCluster(detectCores()-1)
clusterEvalQ(cl,library(MASS))
clusterExport(cl,list("makedata", "backward_lm", "MSE_cv"))
R = parSapply(cl, 1:B, function(i,...) { x <- makedata(n=n); backward_lm(x) } )
MSE_values = matrix(unlist(R["MSE_test",]), nrow = B, byrow = T)
AIC = matrix(unlist(R["AIC",]), nrow = B, byrow = T)
BIC = matrix(unlist(R["BIC",]), nrow = B, byrow = T)
Cp_values  = matrix(unlist(R["Cp",]), nrow = B, byrow = T)
stopCluster(cl)
return(list(MSE_values, AIC=AIC, BIC=BIC, Cp=Cp_values))
}
metric_values()
metric_values(B=5)
metric_values = function(B=3,n=100){
cl = makeCluster(detectCores()-1)
clusterEvalQ(cl,library(MASS))
clusterExport(cl,list("makedata", "backward_lm", "MSE_cv"))
R = parSapply(cl, 1:B, function(i,...) { x <- makedata(n=n); backward_lm(x) } )
MSE_values = matrix(unlist(R["MSE_test",]), nrow = B, byrow = T)
AIC = matrix(unlist(R["AIC",]), nrow = B, byrow = T)
BIC = matrix(unlist(R["BIC",]), nrow = B, byrow = T)
Cp_values  = matrix(unlist(R["Cp",]), nrow = B, byrow = T)
stopCluster(cl)
return(list(MSE=MSE_values, AIC=AIC, BIC=BIC, Cp=Cp_values))
}
metric_values(B=5)
rm(list = ls())
cat("\014")
# Data --------------------------------------------------------------------
makedata=function(p=20,wh=15,n=100){
# This function generates p independent X variables and then uses wh of them
# to generate Y based on coefficients determined by exp(exps) below.
# Outside of the function, the data frame named data is further changed to
# randomize the order of the variables so it's hard to tell for sure which
# ones were used to generate Y.  You can always go back and examine switch
# to figure out if your models include the right variables and which ones.
X=matrix(rnorm(n*p),n,p)
exps=seq(-1,-2.5,length=wh)
beta=rep(0,p)
beta[1:wh]=exp(exps)
Y=.5+X%*%beta+rnorm(n)
data = data.frame(Y,X)
colnames(data)=c("Y",letters[1:20])
switch=sample(20)+1
data=data[,c(1,switch)]
return(data)
}
set.seed(1)
data=makedata()
lmout=lm(Y~.,data=data)
summary(lmout)
coef(summary(lmout))[-1,]
# Criteria ----------------------------------------------------------------
## # Cross validated MSE
MSE_cv = function(data, nfold=10, formula="Y~."){
Y_cv = c()
nrows = nrow(data)
MSE_test = c()
for (i in seq(0, nrows-nfold, by=nrows/nfold)){
test = (i+1):(nfold+i)
train = -test
lm.fit = lm(formula, data=data[train,])
Ytest = predict(lm.fit, data[test,])
MSE_test = c(MSE_test, mean((data$Y[test]-Ytest)^2))
}
return(mean(MSE_test))
}
MSE_cv(data)
# Backward selection ------------------------------------------------------
backward_lm = function(data,nfold=10){
# Initialize with OLS
formula = "Y~."
lm.fit = lm(formula, data=data)
# Initialize outputs
MSE_test = c()
AIC = c()
BIC = c()
Cp = c()
next_to_remove = ""
variables = c()
n = nrow(data)
while(length(names(lm.fit$model))>1){
MSE = MSE_cv(data, nfold=nfold, formula)
MSE_test = c(MSE_test, MSE)
AIC = c(AIC,AIC(lm.fit))
BIC = c(BIC,BIC(lm.fit))
d = length(names(lm.fit$coefficients))-1
Cp = c(Cp, MSE + 2*d*mean((lm.fit$residuals)^2)/n)
t_values = coef(summary(lm.fit))[,"t value"]
# Variable with smallest t-value
next_to_remove = names(which.min(t_values[-1]))
# Store removed variables in the order
variables = c(variables,next_to_remove)
# Update formula
formula = paste(formula,"-",next_to_remove,sep="")
# Update model using new formula
lm.fit = update(lm.fit, formula)
}
# Intercept only
variables = variables
MSE = MSE_cv(data, nfold, formula)
MSE_test = c(MSE_test, MSE)
AIC = c(AIC,AIC(lm.fit))
BIC = c(BIC,BIC(lm.fit))
Cp = c(Cp, MSE)
return(list(variables = rev(variables), MSE_test = MSE_test,
AIC=AIC, BIC=BIC, Cp=Cp))
}
backward = backward_lm(data)
backward
# Generate data and performs backward selection
backward_data = function(n=100,nfold=10){
data = makedata(n=n)
return(backward_lm(data,nfold=nfold))
}
## # REPLICATE
library(parallel)
metric_values = function(B,n=100){
cl = makeCluster(detectCores()-1)
clusterEvalQ(cl,library(MASS))
clusterExport(cl,list("makedata", "backward_lm", "MSE_cv"))
R = parSapply(cl, 1:B, function(i,...)
{ x <- makedata(n=n); backward_lm(x) } )
MSE_values = matrix(unlist(R["MSE_test",]), nrow = B, byrow = T)
AIC = matrix(unlist(R["AIC",]), nrow = B, byrow = T)
BIC = matrix(unlist(R["BIC",]), nrow = B, byrow = T)
Cp_values  = matrix(unlist(R["Cp",]), nrow = B, byrow = T)
stopCluster(cl)
return(list(MSE=MSE_values, AIC=AIC, BIC=BIC, Cp=Cp_values))
}
Rep_backward100 = metric_values(1000,n=100)
stopCluster(cl)
cl = makeCluster(detectCores()-1)
stopCluster(cl)
rm(list = ls())
cat("\014")
install.packages("pls")
install.packages("parallel")
install.packages("parrallel")
install.packages("parallel")
install.packages("parallel")
library(parallel)
quit()
library(knitr)
knit("DoutreThibaultHW11.Rmd")
knit("DoutreThibaultHW11.Rnw")
quit()
