{
    "contents" : "\\documentclass[11pt]{article}\n\\usepackage{amsmath}\n\\usepackage{listings}\n\\usepackage{stmaryrd}\n\\usepackage{bbm}\n\\usepackage{amsmath}\n\\usepackage{mathtools}\n\\usepackage{pdfpages}\n\\usepackage{breqn}\n<<echo=FALSE>>=\n  options(width=60)\n\n  listing <- function(x, options) {\n    paste(\"\\\\begin{lstlisting}[basicstyle=\\\\ttfamily,breaklines=true]\\n\",\n      x, \"\\\\end{lstlisting}\\n\", sep = \"\")\n  }\n  knit_hooks$set(output=listing)\n@\n\n\n\\newcount\\colveccount\n\\newcommand*\\colvec[1]{\n        \\global\\colveccount#1\n        \\begin{pmatrix}\n        \\colvecnext\n}\n\\def\\colvecnext#1{\n        #1\n        \\global\\advance\\colveccount-1\n        \\ifnum\\colveccount>0\n                \\\\\n                \\expandafter\\colvecnext\n        \\else\n                \\end{pmatrix}\n        \\fi\n}\n\\newcommand{\\argmin}{\\arg\\!\\min}\n\n\\author{Thibault Doutre, Student ID 26980469}\n\\title{STAT230 HW 10 \\\\\nUniversity of California, Berkeley}\n\\date{\\today}\n\\begin{document}\n\n\\maketitle\n\\section{}\n<<>>=\n# Load data ----------------------------------------------\n\nload(\"HW10.rda\")\n\n## shuffle\ndata = data[sample(nrow(data)),]\n\n# Full Model, R2 -----------------------------------------\n\n## # OLS fit\nlm.fit = lm(Y~., data=data)\n\n## # R2\nR2 = var(lm.fit$fitted.values)/var(data$Y)\nR2\n\n## # Cross validated R2\n\nR2_cv = function(data, nfold, formula=\"Y~.\"){\n  # Compute R2 based on cross validated data\n  Y_cv = c()\n  nrows = nrow(data)\n  for (i in seq(0, nrows-nfold, by=nrows/nfold)){\n    print(i+1)\n    print(nfold+i)\n    test = i:(nfold+i)\n    train = -test\n    lm.fit = lm(formula, data=data[train,])\n    Ytest = predict(lm.fit, data[test,])\n    Y_cv = c(Y_cv, Ytest)\n  }\n  var(Y_cv)/var(data$Y)\n}\nnames(lm.fit)\nnfold = 10\nR2_cv10 = R2_cv(data, 10)\nR2_cv10\n\n\nsummary(lm.fit)\n@\nThe cross validated $R^2$ is significantly higher than both the multiple and adjusted $R^2$. The $R^2$ computed with the fitted values is approximately equal to the multiple $R^2$ (precision $10^{-4}$).\n\n\\section{}\n\n<<>>=\n\n# Backward selection --------------------------------------\n\n## # Cross validated MSE\n\nMSE_cv = function(data, nfold, formula=\"Y~.\"){\n  # Compute R2 based on cross validated data\n  Y_cv = c()\n  nrows = nrow(data)\n  MSE_test = c()\n  MSE_train = c()\n  for (i in seq(0, nrows-nfold, by=nrows/nfold)){\n    test = (i+1):(nfold+i)\n    train = -test\n    lm.fit = lm(formula, data=data[train,])\n    Ytest = predict(lm.fit, data[test,])\n    MSE_test = c(MSE_test, mean((data$Y[test]-Ytest)^2))\n    MSE_train = c(MSE_train, \n                  mean((data$Y[train]-lm.fit$fitted.values)^2))\n  }\n  # Training error based on best model\n  # Test error based on cross validation (mean)\n  return(list(test = mean(MSE_test), train = min(MSE_train)))\n  \n}\n\nMSE_cv(data, nfold)\n\n## # Remove less significant feature from lm.fit\n\nbackward_lm = function(data){\n  # Initialize with OLS\n  formula = \"Y~.\"\n  lm.fit = lm(formula, data=data)\n  # Initialize outputs\n  MSE_train = c()\n  MSE_test = c()\n  next_to_remove = \"\"\n  variables = c()\n  while(length(names(lm.fit$model))>1){\n    MSE = MSE_cv(data, 10, formula)\n    MSE_train = c(MSE_train, MSE$train)\n    MSE_test = c(MSE_test, MSE$test)\n    t_values = coef(summary(lm.fit))[, \"t value\"]\n    # Variable with smallest t-value\n    next_to_remove = names(which.min(t_values))\n    # Store removed variables in the order\n    variables = c(variables,next_to_remove)\n    # Update formula\n    formula = paste(formula,\"-\",next_to_remove,sep=\"\")\n    # Update model using new formula\n    lm.fit = update(lm.fit, formula)\n  }\n  # Intercept only\n  MSE = MSE_cv(data, 10, formula)\n  MSE_train = c(MSE_train, MSE$train)\n  MSE_test = c(MSE_test, MSE$test)\n  return(list(variables = variables, MSE_test = MSE_test, \n              MSE_train = MSE_train))\n}\n\nbackward = backward_lm(data)\nbackward\n@\n\n\n\\section{}\n<<>>=\n# Forward selection ----------------------------------------\n\nforward_lm = function(data){\n  names = names(data)[-1]\n  # Initialize outputs\n  MSE_train = c()\n  MSE_test = c()\n  variables = c()\n  # Intercept only\n  formula = \"Y~1\"\n  MSE = MSE_cv(data, 10, formula)\n  MSE_train = c(MSE_train, MSE$train)\n  MSE_test = c(MSE_test, MSE$test)\n  while(length(names)>0){\n    ## Find best variable to add to the model\n    best_new = \"\"\n    best_MSE = Inf \n    for (variable in names){\n      formula_test = paste(formula,\"+\",variable,sep=\"\")\n      # Update MSE using the cross validated training MSE\n      MSE = MSE_cv(data, 10, formula_test)$train\n      if (MSE<best_MSE){\n        best_MSE = MSE\n        best_new = variable\n        }\n    }\n    # Update names\n    names = names[-which(names==best_new)]\n    ## Update formula\n    formula = paste(formula,\"+\",best_new,sep=\"\")\n    ## Update data\n    MSE = MSE_cv(data, 10, formula)\n    MSE_train = c(MSE_train, MSE$train)\n    MSE_test = c(MSE_test, MSE$test)\n    variables = c(variables,best_new)\n  }\n  return(list(variables = variables, MSE_test = MSE_test, \n              MSE_train = MSE_train))\n}\n\nforward = forward_lm(data)\nforward\n@\nForward selection and backward selection do not give the same sequence of models here. This is often the case when the number of features is relatively high but the same sequence of models can happen in some cases.\nIndeed, the significance of one feature can depend on the presence or absence of this feature in the model, especially when the varaibles are correlated.\n\n\n\\section{}\n\n<<>>=\n\n# Plot results ---------------------------------------------\n\nymax = max(max(backward$MSE_test,\n               backward$MSE_train,\n               forward$MSE_train,\n               forward$MSE_test))\nymin = min(min(backward$MSE_test,\n               backward$MSE_train,\n               forward$MSE_train,\n               forward$MSE_test))\n\n## Backward selection\n\nplot(rev(backward$MSE_test), col = \"darkblue\", type=\"b\",\n     xlab = \"Number of features\",\n     ylab = \"MSE\",\n     main = \"Forward and Backward selection\",\n     ylim = c(ymin,ymax))\n\nlines(rev(backward$MSE_train), col = \"lightblue\", type=\"b\")\n\nabline(v=which.min(rev(backward$MSE_test)),col=\"darkblue\",\n       lty=2)\nabline(v=which.min(rev(backward$MSE_train)),col=\"lightblue\",\n       lty=2)\n\n\n## Forward selection\n\nlines(forward$MSE_train, col = \"red1\", type=\"b\")\nlines(forward$MSE_test, col = \"darkred\", type=\"b\")\n\nabline(v=which.min(forward$MSE_test),col=\"darkred\",lty=4)\nabline(v=which.min(forward$MSE_train),col=\"red1\",lty=4)\n\n## Legend\nlegend(\"bottomleft\", \n       c(\"Forward-Train\",\"Forward-Test\",\"Backward-Train\",\n         \"Backward-Test\"), \n       col = c(\"red1\",\"darkred\",\"lightblue\",\"darkblue\"),lwd=1)\n\n\n@\nThe train error is decreasing as the number of features grows because we allow more flexibility in the model. As for the test set, there is a minimum corresponding to the optimal trade off between how flexibile the model is and how many noise is added to it with useless features. We talk about overfitting when the model is too flexible.\n\n\n\\end{document}\n\n\n\n\n\n\n\n\n\n",
    "created" : 1460441237780.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "2557897080",
    "id" : "9277AF3F",
    "lastKnownWriteTime" : 1460696182,
    "path" : "~/Documents/stat230A/hw10/DoutreThibaultHW10.Rnw",
    "project_path" : "DoutreThibaultHW10.Rnw",
    "properties" : {
        "tempName" : "Untitled1"
    },
    "relative_order" : 2,
    "source_on_save" : false,
    "type" : "sweave"
}