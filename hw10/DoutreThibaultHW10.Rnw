\documentclass[11pt]{article}
\usepackage{amsmath}
\usepackage{listings}
\usepackage{stmaryrd}
\usepackage{bbm}
\usepackage{amsmath}
\usepackage{mathtools}
\usepackage{pdfpages}
\usepackage{breqn}
<<echo=FALSE>>=
  options(width=60)

  listing <- function(x, options) {
    paste("\\begin{lstlisting}[basicstyle=\\ttfamily,breaklines=true]\n",
      x, "\\end{lstlisting}\n", sep = "")
  }
  knit_hooks$set(output=listing)
@


\newcount\colveccount
\newcommand*\colvec[1]{
        \global\colveccount#1
        \begin{pmatrix}
        \colvecnext
}
\def\colvecnext#1{
        #1
        \global\advance\colveccount-1
        \ifnum\colveccount>0
                \\
                \expandafter\colvecnext
        \else
                \end{pmatrix}
        \fi
}
\newcommand{\argmin}{\arg\!\min}

\author{Thibault Doutre, Student ID 26980469}
\title{STAT230 HW 10 \\
University of California, Berkeley}
\date{\today}
\begin{document}

\maketitle
\section{}
<<>>=
# Load data ----------------------------------------------

load("HW10.rda")

## shuffle
data = data[sample(nrow(data)),]

# Full Model, R2 -----------------------------------------

## # OLS fit
lm.fit = lm(Y~., data=data)

## # R2
R2 = var(lm.fit$fitted.values)/var(data$Y)
R2

## # Cross validated R2

R2_cv = function(data, nfold, formula="Y~."){
  # Compute R2 based on cross validated data
  Y_cv = c()
  nrows = nrow(data)
  for (i in seq(0, nrows-nfold, by=nrows/nfold)){
    print(i+1)
    print(nfold+i)
    test = i:(nfold+i)
    train = -test
    lm.fit = lm(formula, data=data[train,])
    Ytest = predict(lm.fit, data[test,])
    Y_cv = c(Y_cv, Ytest)
  }
  var(Y_cv)/var(data$Y)
}
names(lm.fit)
nfold = 10
R2_cv10 = R2_cv(data, 10)
R2_cv10


summary(lm.fit)
@
The cross validated $R^2$ is significantly higher than both the multiple and adjusted $R^2$. The $R^2$ computed with the fitted values is approximately equal to the multiple $R^2$ (precision $10^{-4}$).

\section{}

<<>>=

# Backward selection --------------------------------------

## # Cross validated MSE

MSE_cv = function(data, nfold, formula="Y~."){
  # Compute R2 based on cross validated data
  Y_cv = c()
  nrows = nrow(data)
  MSE_test = c()
  MSE_train = c()
  for (i in seq(0, nrows-nfold, by=nrows/nfold)){
    test = (i+1):(nfold+i)
    train = -test
    lm.fit = lm(formula, data=data[train,])
    Ytest = predict(lm.fit, data[test,])
    MSE_test = c(MSE_test, mean((data$Y[test]-Ytest)^2))
    MSE_train = c(MSE_train, 
                  mean((data$Y[train]-lm.fit$fitted.values)^2))
  }
  # Training error based on best model
  # Test error based on cross validation (mean)
  return(list(test = mean(MSE_test), train = min(MSE_train)))
  
}

MSE_cv(data, nfold)

## # Remove less significant feature from lm.fit

backward_lm = function(data){
  # Initialize with OLS
  formula = "Y~."
  lm.fit = lm(formula, data=data)
  # Initialize outputs
  MSE_train = c()
  MSE_test = c()
  next_to_remove = ""
  variables = c()
  while(length(names(lm.fit$model))>1){
    MSE = MSE_cv(data, 10, formula)
    MSE_train = c(MSE_train, MSE$train)
    MSE_test = c(MSE_test, MSE$test)
    t_values = coef(summary(lm.fit))[, "t value"]
    # Variable with smallest t-value
    next_to_remove = names(which.min(t_values))
    # Store removed variables in the order
    variables = c(variables,next_to_remove)
    # Update formula
    formula = paste(formula,"-",next_to_remove,sep="")
    # Update model using new formula
    lm.fit = update(lm.fit, formula)
  }
  # Intercept only
  MSE = MSE_cv(data, 10, formula)
  MSE_train = c(MSE_train, MSE$train)
  MSE_test = c(MSE_test, MSE$test)
  return(list(variables = variables, MSE_test = MSE_test, 
              MSE_train = MSE_train))
}

backward = backward_lm(data)
backward
@


\section{}
<<>>=
# Forward selection ----------------------------------------

forward_lm = function(data){
  names = names(data)[-1]
  # Initialize outputs
  MSE_train = c()
  MSE_test = c()
  variables = c()
  # Intercept only
  formula = "Y~1"
  MSE = MSE_cv(data, 10, formula)
  MSE_train = c(MSE_train, MSE$train)
  MSE_test = c(MSE_test, MSE$test)
  while(length(names)>0){
    ## Find best variable to add to the model
    best_new = ""
    best_MSE = Inf 
    for (variable in names){
      formula_test = paste(formula,"+",variable,sep="")
      # Update MSE using the cross validated training MSE
      MSE = MSE_cv(data, 10, formula_test)$train
      if (MSE<best_MSE){
        best_MSE = MSE
        best_new = variable
        }
    }
    # Update names
    names = names[-which(names==best_new)]
    ## Update formula
    formula = paste(formula,"+",best_new,sep="")
    ## Update data
    MSE = MSE_cv(data, 10, formula)
    MSE_train = c(MSE_train, MSE$train)
    MSE_test = c(MSE_test, MSE$test)
    variables = c(variables,best_new)
  }
  return(list(variables = variables, MSE_test = MSE_test, 
              MSE_train = MSE_train))
}

forward = forward_lm(data)
forward
@
Forward selection and backward selection do not give the same sequence of models here. This is often the case when the number of features is relatively high but the same sequence of models can happen in some cases.
Indeed, the significance of one feature can depend on the presence or absence of this feature in the model, especially when the varaibles are correlated.


\section{}

<<>>=

# Plot results ---------------------------------------------

ymax = max(max(backward$MSE_test,
               backward$MSE_train,
               forward$MSE_train,
               forward$MSE_test))
ymin = min(min(backward$MSE_test,
               backward$MSE_train,
               forward$MSE_train,
               forward$MSE_test))

## Backward selection

plot(rev(backward$MSE_test), col = "darkblue", type="b",
     xlab = "Number of features",
     ylab = "MSE",
     main = "Forward and Backward selection",
     ylim = c(ymin,ymax))

lines(rev(backward$MSE_train), col = "lightblue", type="b")

abline(v=which.min(rev(backward$MSE_test)),col="darkblue",
       lty=2)
abline(v=which.min(rev(backward$MSE_train)),col="lightblue",
       lty=2)


## Forward selection

lines(forward$MSE_train, col = "red1", type="b")
lines(forward$MSE_test, col = "darkred", type="b")

abline(v=which.min(forward$MSE_test),col="darkred",lty=4)
abline(v=which.min(forward$MSE_train),col="red1",lty=4)

## Legend
legend("bottomleft", 
       c("Forward-Train","Forward-Test","Backward-Train",
         "Backward-Test"), 
       col = c("red1","darkred","lightblue","darkblue"),lwd=1)


@
The train error is decreasing as the number of features grows because we allow more flexibility in the model. As for the test set, there is a minimum corresponding to the optimal trade off between how flexibile the model is and how many noise is added to it with useless features. We talk about overfitting when the model is too flexible.


\end{document}









